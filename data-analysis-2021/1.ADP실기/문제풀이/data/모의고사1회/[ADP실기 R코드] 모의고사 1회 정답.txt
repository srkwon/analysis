# ADP실기 모의고사 1회 R코드


###################################################################################
#                  1. 정형 데이터마이닝 (사용 데이터 : lotto)                  
###################################################################################


#---------------------------------------------------------------------------------
# Q1) 연관규칙분석을 수행하기 위해 lotto 데이터셋을 transaction 데이터로 변환하시오. 
#     단, 본 분석에서 로또번호가 추첨된 순서는 고려하지 않고 분석을 수행하도록 한다. 
#     그리고 변환된 데이터에서 가장 많이 등장한 
#     상위 10개의 로또번호를 막대그래프로 출력하고 이에 대해 설명하시오.  
#---------------------------------------------------------------------------------


## < Solution >

#작업 디렉토리 설정
setwd("C:/ADP/data")

#데이터 불러오기
lot<-read.csv("lotto.csv")
str(lot)

#na값이 존재하는지 확인
sum(is.na(lot))


##트랜잭션 데이터로 변환
#데이터형태 변형을 위한 패키지 설치 및 로드
install.packages("reshape2")
library(reshape2)

#melt함수를 이용하여 데이터 변환
lot_melt <- melt(lot, id.vars=1) #melt함수를 이용해 열에 있던 회차별 추첨번호 데이터를 행으로 이동
lot_melt2<-lot_melt[,-2]         #추첨순서를 의미하는 열을 lot_melt 데이터에서 삭제한 후 lot_melt2변수에 저장
str(lot_melt2)                   #변환된 데이터의 형태 확인

#트랜잭션 데이터 생성을 위한 패키지 설치 및 로드
install.packages("arules")
library(arules)


#lot_melt2 데이터를 transaction Data로 변환
#참고) split(x1,x2): x1데이터를 x2에 따라 데이터를 분리하는 함수
#참고) as(데이터, "transactions"): 데이터의 구조를 트랜잭션 데이터로 변환

lot_sp<-split(lot_melt2$value, lot_melt2$time_id)  #로또 추첨회차를 기준으로 당첨번호를 분리하여 lot_sp에 저장
lot_ts<-as(lot_sp, "transactions")                 #lot_sp 데이터를 트랜잭션 데이터로 변환

#트랜잭션 데이터 출력
#참고) inspect(): 트랜잭션 데이터를 출력하는 함수
#inspect 함수를 실행했을 때, 오류가 발생한다면 기존에 활성화된패키지 충돌입니다.(tm과 arules)
#해당 오류를 해결하기 위해서는 아래와 같이 코드를 실행하시면 됩니다.
#arules::inspect(lot_ts[1:5])

inspect(lot_ts[1:5])  #트랜잭션 데이터로 변환한 후 다섯개의 행을 출력하여 확인


#최다 등장 로또추첨번호 TOP 10을 확인한 후 막대그래프로 시각화하기
#참고) itemFrequencyPlot(): 트랜잭션 데이터에서 거래 품목별로 거래에서 차지하는 비율이나 거래건수를 막대그래프 형태로 출력
#                          (본 분석에서는 로또 한 회차가 하나의 거래와도 같은 개념이다.)

itemFrequencyPlot(lot_ts,topN=10,type="absolute") #도수를 기준으로 막대그래프 생성
itemFrequencyPlot(lot_ts,topN=10)                 #상대도수(비율)를 기준으로 막대그래프 생성
#--결과해석
# 대부분의 번호가 유사한 빈도로 추첨되었으나, 
# 34번이 그 중에서도 가장 많이 추첨된 것을 확인할 수 있다.




#-------------------------------------------------------------------------------------
# Q2) 변환한 데이터에 대해 apriori함수를 사용하여 다음 괄호 안의 조건을 반영하여 
#     연관규칙을 생성하고, 이를 ‘rules_1’이라는 변수에 저장하여 결과를 해석하시오. 
#     (최소 지지도 : 0.002, 최소 신뢰도 : 0.8, 최소조합 항목 수 : 2개, 최대조합 항목 수 : 6개) 
#     그리고 도출된 연관규칙들을 향상도를 기준으로 내림차순 정렬하여 상위 30개의 규칙을 확인하고, 
#     이를 데이터프레임으로 변환하여 csv파일로 출력하시오.  
#-------------------------------------------------------------------------------------


## < Solution >

#규칙 생성
#참고) apriori(data, parameter) : apriori알고리즘을 이용하여 연관규칙을 찾는 함수

#최소 지지도, 신뢰도, 조합 항목수에 대한 조건을 리스트형태로 저장
metric.params <- list(supp=0.002, conf=0.8, minlen=2, maxlen=6)       
rules_1 <- apriori(lot_ts, parameter = metric.params)
inspect(rules_1[1:20])
#--총 679개의 연관규칙이 발견되었다. 


#향상도인 "lift"기준으로 내림차순 정렬했을 때 상위 30개의 규칙 확인
rules_2 <- sort(rules_1, by="lift", decreasing=TRUE) #향상도를 기준으로 내림차순 정렬
inspect(rules_2[1:30])                               #상위 30개의 규칙 확인

#위 30개의 규칙들을 데이터프레임으로 변환
rules_3<-inspect(rules_2[1:30])  
rules_4<-as(rules_3, "data.frame")
str(rules_4)


#변환된 데이터프레임을 csv파일로 저장
write.csv(rules_4,file="C:/ADP/data/lotto_rules.csv",row.names=FALSE)





#---------------------------------------------------------------------------------------
# Q3) 생성된 연관규칙 'rules_1'에 대한 정보를 해석하고, 1)번 문제를 통해 확인했을 때 
#     가장 많이 추첨된 번호가 우측항에 존재하는 규칙들만을 ‘rules_most_freq’라는 변수에 저장하시오. 
#     그리고 해당 규칙들을 해석하여 인사이트를 도출한 후 서술하시오.
#---------------------------------------------------------------------------------------

## < Solution >

#summary함수를 이용하여 생성된 규칙들에 관한 정보를 해석
summary(rules_1)
##--결과해석
# 총 679개의 연관규칙이 도출되었으며, 그 중 632개의 규칙은 4개의 로또번호로 구성되었고
# 47개의 규칙은 5개의 번호로 구성되었다.
# 규칙들에 대한 향상도의 최소값은 6.410으로 꽤 높게 나타났으며,
# 추첨번호들의 교집합 확률을 의미하는 지지도의 평균은 0.002364로 나타났다.
# 트랜잭션 데이터의 개수는 859개이며, 
# 트랜잭션 데이터는 859회 동안의 로또 당첨번호들을 의미한다.


#로또 데이터에서 가장 많이 등장한 추첨번호 '34'가 우측항에 존재하는 규칙들만을 추출하여 저장
rules_most_freq<-subset(rules_1, rhs %in% "34")

#해당 규칙 확인
inspect(rules_most_freq)
##--결과 해석
# 총 19개의 규칙이 도출되었으며,
# [1]번 규칙을 확인해 보면, {7, 22, 31}번과 {34}번이 함께 추첨될 확률은
# support(지지도)를 확인한 결과 0.002328289이며 이는 약 0.2%에 해당한다.
# 이 규칙의 lift(향상도)는 6.410448로 이는 {34}만 추첨됐을 때 보다
# {7, 22, 31}번이 뽑히고 {34}도 뽑힐 확률이 약 6배 높다는 것을 의미한다.
# 하지만 이러한 규칙들은 로또번호가 추첨되는 순서를 고려하지 않고 
# 단순히 조합에 대한 확률만을 고려한 규칙이므로,
# 향상도가 높은 숫자들의 조합이 로또 추첨번호가 될 가능성이 높은 것은 아니다.

###################################################################################
#                      2. 통계분석 (사용 데이터 : )                  
###################################################################################

#---------------------------------------------------------------------------------------
# Q1) FIFA데이터에서 각 선수의 키는 Heghit변수에 피트와 인치로 입력되어 있습니다. 
#      이를 cm로 변환하여 새로운 변수 Height_cm을 생성하시오. 
#      ( “ ' ” 앞의 숫자는 피트이며, “ ' ” 뒤의 숫자는 인치, 1피트 = 30cm, 1인치 = 2.5cm)
#---------------------------------------------------------------------------------------

#fifa.csv 데이터를 R에서 읽어온 뒤, 데이터의 구조와 요약을 확인한다.
#작업 디렉토리 설정
setwd("C:/ADP/data")

#데이터 불러오기
fifa<-read.csv("FIFA.csv")
str(fifa)
head(fifa)

#na값이 존재하는지 확인
sum(is.na(fifa))

#Height 변수의 피트, 인치 단위로 저장된 키 값을 cm 단위의 값으로 변환하기
#원활한 연산을 위해 Height 변수를 문자형으로 변환
fifa$Height<-as.character(fifa$Height)
 
# "'" 앞의 숫자는 피트이며, "'" 뒤의 숫자는 인치를 의미함
#따라서, "'" 앞 숫자를 추출하여 30을 곱하고, "'" 뒤 숫자를 추출하여 2.5를 곱한 뒤 두 숫자를 더하여 cm단위 값으로 변환
as.numeric(substr(fifa$Height,1,regexpr("'", fifa$Height)-1)) * 30 + 
+ as.numeric(substr(fifa$Height,regexpr("'", fifa$Height)+1, nchar(fifa$Height))) * 2.5

#단위를 변환한 값을 Height_cm 변수에 저장
fifa$Height_cm <- as.numeric(substr(fifa$Height,1,regexpr("'", fifa$Height)-1)) * 30 + 
+                   as.numeric(substr(fifa$Height,regexpr("'", fifa$Height)+1, nchar(fifa$Height))) * 2.5


#---------------------------------------------------------------------------------------
# Q2) 포지션을 의미하는 Position변수를 아래 표를 참고하여 “Forward”, “Midfielder”, 
#      “Defender”, “GoalKeeper”로 재범주화하고, factor형으로 변환하여 Position_Class 
#       라는 변수를 생성하고 저장하시오.
#---------------------------------------------------------------------------------------

#선수의 포지션을 의미하는 Position변수를 문제에 주어진 조건에 맞게 재범주화하여 Position_Class 라는 변수에 저장
fifa<-within(fifa,
 {
 Position_Class=character(0)
 Position_Class[ Position %in% c("LS", "ST", "RS", "LW", "LF", "CF", "RF", "RW") ]="Forward"
       Position_Class[ Position %in% c("LAM", "CAM", "RAM", "LM", "LCM", "CM", "RCM", "RM") ]="Midfielder"
       Position_Class[ Position %in% c("LWB", "LDM", "CDM", "RDM", "RWB", "LB", "LCB", "CB", "RCB", "RB") ]="Defender"
       Position_Class[ Position == "GK" ]="GoalKeeper"
       })


# Position_Class변수를 팩터형(factor)으로 변환
fifa$Position_Class<-factor(fifa$Position_Class, levels=c("Forward", "Midfielder", "Defender", "GoalKeeper"),
                      labels=c("Forward", "Midfielder", "Defender", "GoalKeeper"))
str(fifa)

#---------------------------------------------------------------------------------------
# Q3) 새로 생성한 Position_Class 변수의 각 범주에 따른 Value(선수의 시장가치)의 
#      평균값의 차이를 비교하는 일원배치 분산분석을 수행하고 결과를 해석하시오. 
#      그리고 평균값의 차이가 통계적으로 유의하다면 사후검정을 수행하고 설명하시오.
#---------------------------------------------------------------------------------------

# 분산분석 수행
fifa_result<-aov(Value~Position_Class, data=fifa) #분산분석 결과를 result 변수에 저장
summary(fifa_result)                              #분산분석표 확인

TukeyHSD(aov(Value~Position_Class, data=fifa))

#---------------------------------------------------------------------------------------
# Q4) Preferred Foot(주로 사용하는 발)과 Position_Class(재범주화 된 포지션)변수에 
#      따라 Value(이적료)의 차이가 있는지를 알아보기 위해 이원배치분산분석을 
#      수행하고 결과를 해석하시오.
#---------------------------------------------------------------------------------------

# 이원배치 분산분석 수행
fifa_twoway_anova <- aov(Value ~ Preferred_Foot + Position_Class + 
                           Preferred_Foot:Position_Class, data=fifa)
summary(fifa_twoway_anova)

#---------------------------------------------------------------------------------------
# Q5)Age, Overall, Wage, Height_cm, Weight_lb 가 Value에 영향을 미치는지 
#     알아보는 회귀분석을 단계적 선택법을 사용하여 수행하고 결과를 해석하시오. 
#---------------------------------------------------------------------------------------

#단계선택법을 통한 변수선택 수행
step(lm(Value~1, data=fifa), scope=list(lower=~1, 
      upper=~Age + Overall + Wage + Height_cm + Weight_lb), direction="both")

#변수선택을 통해 도출된 회귀모형
fifa.lm <- lm(Value ~ Wage + Overall + Age + Height_cm, data = fifa)
summary(fifa.lm)

###################################################################################
#                      3. 비정형 데이터마이닝 (사용 데이터 : "영화 review")
###################################################################################

#---------------------------------------------------------------------------
# Q1) ‘영화 기생충_review.txt’ 데이터를 읽어온 뒤 숫자, 특수 문자 등을 
#     제거하는 전처리 작업을 시행하시오. 그리고 ‘영화 기생충_review.txt’을 사전에 등록하라.
#---------------------------------------------------------------------------
install.packages(c("KoNLP","wordcloud"))
install.packages("rJava")
install.packages("tm")
install.packages("plyr")
library(tm)
library(rJava)
library(KoNLP)
library(wordcloud)
library(plyr)
library(stringr)

useSejongDic()

movie<-readLines("영화 기생충_review.txt")
dic<-readLines("영화 기생충_사전.txt")

buildDictionary(ext_dic = "woorimalsam", user_dic=data.frame(readLines("영화 기생충_사전.txt"),"ncn"),replace_usr_dic = T)

movie[1:10]

clean_txt<-function(txt){
  txt<-tolower(txt)             # 대, 소문자 변환
  txt<-removePunctuation(txt)   # 구두점 제거
  txt<-removeNumbers(txt)       # 숫자 제거
  txt<-stripWhitespace(txt)     # 공백제거
  
  return(txt)
}

movie_clean<-clean_txt(movie)

movie_clean[1:10]

#---------------------------------------------------------------------------
# Q2) ‘영화 기생충_사전.txt’를 단어 사전으로 하는 TDM을 구축하고 빈도를 파악하고 시각화하라.
#---------------------------------------------------------------------------

b<-VCorpus(VectorSource(movie))

clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, content_transformer(tolower))
  return(corpus)
}

c<-clean_corpus(b)

dtm<-TermDocumentMatrix(c,control=list(dictionary=dic))

m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE) 
d <- data.frame(word = names(v),freq=v)
head(d, 12)

#시각화
colors<-rainbow(nrow(d))

barplot(v[1:10], main="기생충 review 빈출 명사",col=colors)
legend("right",names(v[1:10]),fill=colors)

#---------------------------------------------------------------------------
# Q3) extraNoun으로 명사를 추출하여 워드클라우드를 그리고 특성을 파악하시오.
#---------------------------------------------------------------------------

#명사 추출
movie_exN<-sapply(movie_clean,extractNoun)
Noun<-as.vector(unlist(movie_exN))
Noun_2<-Noun[nchar(Noun)>=2]

#워드클라우드 시각화
result<-data.frame(sort(table(Noun_2),decreasing=T))
t<-wordcloud(result$Noun_2,result$Freq,color=brewer.pal(8,"Dark2"),min.freq=30)
