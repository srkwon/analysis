# ADP실기 모의고사 4회 R코드


###################################################################################
#                      1. 정형 데이터마이닝 (사용 데이터 : weatherAUS)                  
###################################################################################

#---------------------------------------------------------------------------------------
# Q1) 데이터의 요약값을 보고 NA값이 10,000개 이상인 열을 제외하고 남은 변수 중 NA값이 있는 행을 제거하시오. 
#     그리고 AUS 데이터의 Date 변수를 Date형으로 변환하고, 
#     전처리가 완료된 weatherAUS 데이터를 train(70%), test(30%) 데이터로 분할하시오.
#     (set.seed(6789)를 실행한 후 데이터를 분할하시오.)
#---------------------------------------------------------------------------------------


##데이터 불러오기
AUS<-read.csv("weatherAUS.csv")

summary(AUS)

#"WindDir9am", "Pressure9am", "Pressure3pm", "Cloud9am", "Cloud3am"는 NA's가 10000개 이상이므로 데이터에서 제외
AUS_1<-AUS[,c("Date","Location","MinTemp","MaxTemp","Rainfall","WindGustDir","WindGustSpeed",
              "WindDir3pm","WindSpeed9am","WindSpeed3pm","Humidity9am","Humidity3pm",
              "Temp9am","Temp3pm","RainToday","RainTomorrow" )]

summary(AUS_1)

AUS_1$Date<-as.Date(AUS_1$Date) 
str(AUS_1)


#결측치 삭제
str(AUS_1)
AUS_1<-na.omit(AUS_1)

str(AUS_1)           #약 12,000개가 삭제됨

#데이터 분할
install.packages("caret")
library(caret)

set.seed(6789)
parts<-createDataPartition(AUS_1$RainTomorrow, p=0.7)
idx<-as.vector(parts[[1]])

train<-AUS_1[idx,]
test<-AUS_1[-idx,]
nrow(train)
nrow(test)

#---------------------------------------------------------------------------------------
# Q2) train 데이터로 종속변수인 RainTomorrow(다음날의 강수 여부)를 예측하는 분류모델을 
#     3개 이상 생성하고 test 데이터에 대한 예측값을 csv파일로 각각 제출하시오.
#---------------------------------------------------------------------------------------

install.packages(c("ipred","adabag","e1071","caret","randomForest"))
library(ipred)
library(e1071)
library(caret)
library(adabag)
library(randomForest)

#모델링 (1) bagging(깊이를 최대 5개까지,노드에서 최소 관측치는 15개 이상, 사용할 나무 15개)
#pred_1을 실행했을 때, 오류가 발생한다면 bagging 모델 개발 시, 활성화된 패키지 충돌이 원인입니다.(ipred과 adabag)
#해당 오류를 해결하기 위해서는 아래와 같이 코드를 실행하시면 됩니다.
#bg.model <- adabag::bagging(RainTomorrow~., data=train, mfinal=15, control = rpart.control(maxdepth=5, minsplit=15))

bg.model <- bagging(RainTomorrow~., data=train, mfinal=15, control = rpart.control(maxdepth=5, minsplit=15))

pred<-predict(bg.model,test[,-16],type="prob")

pred_1<-data.frame(pred$prob,RainTomorrow=pred$class)

head(pred_1)

write.csv(pred,"bagging predict.csv")

pred<-predict(bg.model,test[,-16],type="class")
table(pred$class,test[,16])

#모델링 (2) boosting(깊이를 최대 5개까지,노드에서 최소 관측치는 15개 이상, 사용할 나무 15개, 모든 관측치에 동일한 가중치)

bs.model <- boosting(RainTomorrow~., data=train, boos=FALSE, mfinal=15, control = rpart.control(maxdepth=5, minsplit=15))

pred<-predict(bs.model,test[,-16],type="prob")

pred_1<-data.frame(pred$prob,RainTomorrow=pred$class)

head(pred_1)

write.csv(pred_1,"bagging predict.csv")


#모델링 (3) 랜덤 포레스트
install.packages("randomForest")
library(randomForest)

rf.model<-randomForest(RainTomorrow~., data=train)
print(rf.model)

pred<-predict(rf.model,test[,-16],type="prob")

write.csv(pred,"randomForest predict.csv")


#---------------------------------------------------------------------------------------
# Q3) 생성된 3개의 분류모델에 대해 성과분석을 실시하여 정확도를 비교하여 설명하시오. 
#     또, ROC curve를 그리고 AUC값을 산출하시오.
#---------------------------------------------------------------------------------------

## < Solution >

#성과분석 - (1) bagging
install.packages(c("caret","ROCR"))
library(caret)
library(ROCR)

pred.bg<-predict(bg.model,test[,-16],type="class")
table(pred.bg$class,test[,16])

confusionMatrix(data=as.factor(pred.bg$class), reference=test[,16],positive="No")

#prediction 함수를 실행했을 때, 오류가 발생한다면 기존에 활성화된패키지 충돌입니다.(ROCR과 neuralnet)
#해당 오류를 해결하기 위해서는 아래와 같이 코드를 실행하시면 됩니다.
#pred.bg.roc<-ROCR::prediction(as.numeric(as.factor(pred.bg$class)),as.numeric(test[,16]))

pred.bg.roc<-prediction(as.numeric(as.factor(pred.bg$class)),as.numeric(test[,16]))
plot(performance(pred.bg.roc,"tpr","fpr"))
abline(a=0,b=1,lty=2,col="black")
performance(pred.bg.roc,"auc")@y.values

#성과분석 - (2) boosting

pred.bs<-predict(bs.model,test[,-16],type="class")

confusionMatrix(data=as.factor(pred.bs$class), reference=test[,16], positive="No")

#prediction 함수를 실행했을 때, 오류가 발생한다면 기존에 활성화된패키지 충돌입니다.(ROCR과 neuralnet)
#해당 오류를 해결하기 위해서는 아래와 같이 코드를 실행하시면 됩니다.
#pred.bs.roc<-ROCR::prediction(as.numeric(as.factor(pred.bs$class)),as.numeric(test[,16]))

pred.bs.roc<-prediction(as.numeric(as.factor(pred.bs$class)),as.numeric(test[,16]))
plot(performance(pred.bs.roc,"tpr","fpr"))
abline(a=0,b=1,lty=2,col="black")
performance(pred.bs.roc,"auc")@y.values

#성과분석 - (3) 랜덤 포레스트

pred.rf<-predict(rf.model,test[,-16],type="class")
confusionMatrix(data=pred.rf, reference=test[,16],positive="No")

#prediction 함수를 실행했을 때, 오류가 발생한다면 기존에 활성화된패키지 충돌입니다.(ROCR과 neuralnet)
#해당 오류를 해결하기 위해서는 아래와 같이 코드를 실행하시면 됩니다.
#pred.rf.roc<-ROCR::prediction(as.numeric(pred.rf),as.numeric(test[,16]))

pred.rf.roc<-prediction(as.numeric(pred.rf),as.numeric(test[,16]))
plot(performance(pred.rf.roc,"tpr","fpr"))
abline(a=0,b=1,lty=2,col="black")
performance(pred.rf.roc,"auc")@y.values



###################################################################################
#                     2. 통계분석 (사용 데이터 : bike_marketing)               
###################################################################################


#---------------------------------------------------------------------------------
# Q1) pop_density 변수를 factor형 변수로 변환하고, 
#     pop_density별 revenues의 평균 차이가 있는지 통계분석을 시행하여 결과를 해석하시오. 
#     만일 대립가설이 채택된다면 사후분석을 실시하고 결과를 해석하시오.
#---------------------------------------------------------------------------------


## < Solution >

#작업 디렉토리 설정
setwd("C:/ADP/data")

#데이터 불러오기
bike <-read.csv("bike_marketing.csv")

str(bike)    
head(bike)
tail(bike)

sum(is.na(bike))  #NA값이 존재하는지 확인

# pop_density 변수를 factor형 변수로 변환
bike$pop_density<-as.factor(bike$pop_density)
str(bike)


# pop_density별 revenues의 평균 차이가 있는지를 알아보기위한 일원배치 분산분석 수행
# 귀무가설 : 인구밀집정도에 따른 revenues의 평균은 모두 같다.
# 대립가설 : 적어도 하나의 밀집정도 수준에 대한 revenues의 평균값에는 차이가 있다. 


# 분산분석 수행
result<-aov(revenues~pop_density, data=bike) #분산분석 결과를 result 변수에 저장
summary(result)                              #분산분석표 확인


#----------------------------------------------------------------------------------------
# Q2) google_adwords, facebook, twitter, marketing_total, employees가 
#     revenues에 영향을 미치는지 알아보는 회귀분석을 전진선택법을 사용하여 수행하고 결과를 해석하시오.
#----------------------------------------------------------------------------------------


## < Solution >
# 회귀모형 생성
bike.lm <- lm(revenues ~ google_adwords + facebook + twitter + 
                marketing_total + employees, data=bike)



# 회귀모형에 대한 정보 확인
summary(bike.lm)


# 전진선택법을 통한 변수선택 수행
# 변수 선택의 상한과 하한에 대한 포뮬러 생성
formula_low <- lm(revenues ~ 1, data=bike) 
formula_up <- lm(revenues ~ google_adwords + facebook + twitter + 
                   marketing_total + employees, data=bike) 

# step함수를 이용해 전진선택법 진행
step(formula_low, scope=list(upper=formula_up), direction="forward")
# 인자 설명 => upper인자 : 변수선택을 진행할 때 모델의 상한범위



#---------------------------------------------------------------------------
# Q3) 전진선택법을 사용해 변수를 선택한 후 새롭게 생성한 회귀모형에 대한 
#     잔차분석을 수행하고 결과를 해석하시오. 
#---------------------------------------------------------------------------


## < Solution >

#독립성 가정을 만족하는지 확인 (더빈왓슨 검정)
install.packages("lmtest")  #더빈왓슨 검정을 위해 필요한 패키지 설치
library(lmtest)

dwtest(bike.lm)


#정규성 가정을 만족하는지 확인
shapiro.test(resid(bike.lm))


#등분산성, 정규성 가정을 만족하는지 확인
par(mfrow=c(2,2))
plot(bike.lm)  



###################################################################################
#                      3. 비정형 데이터마이닝 (사용 데이터 : "instagram_태교여행")
###################################################################################

#---------------------------------------------------------------------------
# Q1) ‘instagram_태교여행.txt’ 데이터를 읽어온 뒤 숫자, 특수 문자 등을 
#     제거하는 전처리 작업을 시행하시오.
#---------------------------------------------------------------------------

install.packages(c("KoNLP","wordcloud"))
install.packages("rJava")
install.packages("tm")
install.packages("plyr")
library(tm)
library(rJava)
library(KoNLP)
library(wordcloud)
library(plyr)
library(stringr)

useSejongDic()

instagram_tour<-readLines("instagram_태교여행.txt")

#데이터 전처리
clean_txt<-function(txt){
  txt<-tolower(txt)             # 대, 소문자 변환
  txt<-removePunctuation(txt)   # 구두점 제거
  txt<-removeNumbers(txt)       # 숫자 제거
  txt<-stripWhitespace(txt)     # 공백제거
  
  return(txt)
}
tour_1<-clean_txt(instagram_tour)

#---------------------------------------------------------------------------
# Q2) 전처리된 데이터에서 “태교여행”이란 단어를 사전에 추가하고 명사를 추출해 
#     출현빈도 10위까지 막대그래프로 시각화하시오. 
#---------------------------------------------------------------------------

buildDictionary(ext_dic = "woorimalsam", user_dic=data.frame(c("태교여행"),"ncn"),replace_usr_dic = T)

tour1<-sapply(tour_1,extractNoun)

table.cnoun<-head(sort(table(unlist(tour1)),decreasing=T),10)

barplot(table.cnoun, main="tour 데이터 빈출 명사", 
        xlab="단어",
        ylab="빈도")

# 3) 전처리된 데이터를 이용해 워드클라우드를 작성하고 인사이트를 추출하시오.

result<-data.frame(sort(table(unlist(tour1)),decreasing=T))

t<-wordcloud(result$Var1,result$Freq,color=brewer.pal(6,"Dark2"),min.freq=20)
