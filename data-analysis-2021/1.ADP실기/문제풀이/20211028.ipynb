{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74119182",
   "metadata": {},
   "source": [
    "# 모의고사 4회 문제 풀이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09096892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(142193, 21) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am',\n",
      "       'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',\n",
      "       'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm',\n",
      "       'RainToday', 'RainTomorrow'],\n",
      "      dtype='object')\n",
      "shape=(142193, 16) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm',\n",
      "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
      "       'RainTomorrow'],\n",
      "      dtype='object')\n",
      "shape=(128576, 16) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm',\n",
      "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
      "       'RainTomorrow'],\n",
      "      dtype='object') df3=         Date Location  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
      "0  2008-12-01   Albury     13.4     22.9       0.6           W           44.0   \n",
      "1  2008-12-02   Albury      7.4     25.1       0.0         WNW           44.0   \n",
      "2  2008-12-03   Albury     12.9     25.7       0.0         WSW           46.0   \n",
      "3  2008-12-04   Albury      9.2     28.0       0.0          NE           24.0   \n",
      "4  2008-12-05   Albury     17.5     32.3       1.0           W           41.0   \n",
      "\n",
      "  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Temp9am  \\\n",
      "0        WNW          20.0          24.0         71.0         22.0     16.9   \n",
      "1        WSW           4.0          22.0         44.0         25.0     17.2   \n",
      "2        WSW          19.0          26.0         38.0         30.0     21.0   \n",
      "3          E          11.0           9.0         45.0         16.0     18.1   \n",
      "4         NW           7.0          20.0         82.0         33.0     17.8   \n",
      "\n",
      "   Temp3pm RainToday RainTomorrow  \n",
      "0     21.8        No           No  \n",
      "1     24.3        No           No  \n",
      "2     23.2        No           No  \n",
      "3     26.5        No           No  \n",
      "4     29.7        No           No   describe=             MinTemp        MaxTemp       Rainfall  WindGustSpeed  \\\n",
      "count  128576.000000  128576.000000  128576.000000  128576.000000   \n",
      "mean       12.141033      23.307020       2.299270      40.055679   \n",
      "std         6.427982       7.128457       8.349637      13.525466   \n",
      "min        -8.500000      -4.800000       0.000000       6.000000   \n",
      "25%         7.500000      17.900000       0.000000      31.000000   \n",
      "50%        11.900000      22.800000       0.000000      39.000000   \n",
      "75%        16.800000      28.400000       0.600000      48.000000   \n",
      "max        33.900000      48.100000     367.600000     135.000000   \n",
      "\n",
      "        WindSpeed9am   WindSpeed3pm    Humidity9am    Humidity3pm  \\\n",
      "count  128576.000000  128576.000000  128576.000000  128576.000000   \n",
      "mean       14.236872      18.869424      68.519840      50.915015   \n",
      "std         8.767792       8.603291      19.245898      20.827152   \n",
      "min         0.000000       2.000000       0.000000       0.000000   \n",
      "25%         7.000000      13.000000      56.000000      36.000000   \n",
      "50%        13.000000      19.000000      69.000000      51.000000   \n",
      "75%        20.000000      24.000000      83.000000      65.000000   \n",
      "max        87.000000      87.000000     100.000000     100.000000   \n",
      "\n",
      "             Temp9am        Temp3pm  \n",
      "count  128576.000000  128576.000000  \n",
      "mean       16.970729      21.798451  \n",
      "std         6.529362       6.987518  \n",
      "min        -7.200000      -5.400000  \n",
      "25%        12.200000      16.600000  \n",
      "50%        16.700000      21.300000  \n",
      "75%        21.600000      26.600000  \n",
      "max        40.200000      46.700000  \n",
      "x_train=(90003, 10), x_test=(38573, 10), y_train=(90003,), y_test=(38573,)\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#                      1. 정형 데이터마이닝 (사용 데이터 : weatherAUS)                  \n",
    "###################################################################################\n",
    "#---------------------------------------------------------------------------------------\n",
    "# Q1) 데이터의 요약값을 보고 NA값이 10,000개 이상인 열을 제외하고 남은 변수 중 NA값이 있는 행을 제거하시오. \n",
    "#     그리고 AUS 데이터의 Date 변수를 Date형으로 변환하고, \n",
    "#     전처리가 완료된 weatherAUS 데이터를 train(70%), test(30%) 데이터로 분할하시오.\n",
    "#     (set.seed(6789)를 실행한 후 데이터를 분할하시오.)\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "df = pd.read_csv('./data/모의고사4회/weatherAUS.csv')\n",
    "\n",
    "# 행과 열 개수 확인\n",
    "# 142193개 관측치, 21개 변수\n",
    "print(f'shape={df.shape} columns={df.columns}')\n",
    "#print(df.Location.value_counts())\n",
    "\n",
    "# NA값이 10000개 이상인 열을 제외\n",
    "df2 = df.dropna(\n",
    "    axis = 'columns' # 열을 제외\n",
    "    , thresh =  142193 - 9999   # N개 이상의 non-NA값을 갖고 있는 것만 남김\n",
    "                                # 즉, NA가 아닌 값이 (142193 - 9999) 개수만큼 되는 것만 남기는 것\n",
    ")\n",
    "\n",
    "print(f'shape={df2.shape} columns={df2.columns}')\n",
    "\n",
    "#남은 변수중 NA값이 1개라도 있는 행은 모두 제외\n",
    "df3 = df2.dropna() # dropna의 기본 동작이 모든 컬럼에 대해서 NA가 하나라도 있으면 그 행을 제외\n",
    "\n",
    "print(f'shape={df3.shape} columns={df3.columns} df3={df3.head()} describe={df3.describe()}')\n",
    "\n",
    "# Date 변수를 Date형으로 변환(python datetime을 이용)\n",
    "df3['Date'].apply(lambda x : datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    df3[['MinTemp', 'MaxTemp', 'Rainfall',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm',\n",
    "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm']]\n",
    "    , df3['RainTomorrow']\n",
    "    , train_size = 0.7\n",
    "    , test_size = 0.3\n",
    "    , random_state = 0\n",
    ")\n",
    "\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, y_train={y_train.shape}, y_test={y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9240317",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-8047085ddd7f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;31m# KNN\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mKNeighborsClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"train set accurate = {model.score(x_train, y_train):0.3f}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------\n",
    "# Q2) train 데이터로 종속변수인 RainTomorrow(다음날의 강수 여부)를 예측하는 분류모델을 \n",
    "#     3개 이상 생성하고 test 데이터에 대한 예측값을 csv파일로 각각 제출하시오.\n",
    "#---------------------------------------------------------------------------------------\n",
    "# K-NN, SVM, DT, 나이브베이즈, 로지스틱 회귀, ANN, 랜덤포레스트, 배깅, 부스팅\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel = 'rbf', C = 10, gamma = 0.1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# DT\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "tree.plot_tree(decision_tree = model)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "174be9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------\n",
    "# Q3) 생성된 3개의 분류모델에 대해 성과분석을 실시하여 정확도를 비교하여 설명하시오. \n",
    "#     또, ROC curve를 그리고 AUC값을 산출하시오.\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d24a924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(172, 8), columns=Index(['company_num', 'google_adwords', 'facebook', 'twitter',\n",
      "       'marketing_total', 'revenues', 'employees', 'pop_density'],\n",
      "      dtype='object')\n",
      "   company_num  google_adwords  facebook  twitter  marketing_total  revenues  \\\n",
      "0            1           65.66     47.86    52.46              166     39.26   \n",
      "1            2           39.10     55.20    77.40              172     38.90   \n",
      "2            3          174.81     52.01    68.01              295     49.51   \n",
      "3            4           34.36     61.96    86.86              183     40.56   \n",
      "4            5           78.21     40.91    30.41              150     40.21   \n",
      "\n",
      "   employees pop_density  \n",
      "0          5        High  \n",
      "1          7      Medium  \n",
      "2         11      Medium  \n",
      "3          7        High  \n",
      "4          9         Low  \n",
      "Low       68\n",
      "High      52\n",
      "Medium    52\n",
      "Name: pop_density, dtype: int64\n",
      "귀무가설 : pop_density별 revenues의 평균 차이는 없다.(모두 동일하다.)\n",
      "대립가설 : pop_density별 revenues의 평균 차이가 적어도 하나 존재한다.\n",
      "통계적 추론에서 유의수준은 다른 말이 없으면 5%(0.05)로 지정\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.609944214128908, pvalue=0.544572945313452)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################\n",
    "#                     2. 통계분석 (사용 데이터 : bike_marketing)               \n",
    "###################################################################################\n",
    "#---------------------------------------------------------------------------------\n",
    "# Q1) pop_density 변수를 factor형 변수로 변환하고, \n",
    "#     pop_density별 revenues의 평균 차이가 있는지 통계분석을 시행하여 결과를 해석하시오. \n",
    "#     만일 대립가설이 채택된다면 사후분석을 실시하고 결과를 해석하시오.\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "# 3개 이상 범주에 대한 평균 차이 검정 => 일원 배치 분산분석(F 검정 통계량) - one way ANOVA => 귀무가설 기각시 사후검정 tukey HSD 수행\n",
    "# https://www.pythonfordatascience.org/anova-python/ 확인\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv('./data/모의고사4회/bike_marketing.csv')\n",
    "\n",
    "print(f\"shape={df.shape}, columns={df.columns}\")\n",
    "print(df.head())\n",
    "\n",
    "# pop_density 종류별 개수 파악\n",
    "print(df['pop_density'].value_counts()) # Low, Medium, High 3가지 종류가 있음\n",
    "\n",
    "# pop_density 별 revenues 를 정렬하여 별개 데이터 소스로 추출\n",
    "#print(df[df['pop_density'] == 'High']['revenues'])\n",
    "\n",
    "# 통계적 추론 과정\n",
    "# 귀무가설, 대립가설 설정\n",
    "print(\"귀무가설 : pop_density별 revenues의 평균 차이는 없다.(모두 동일하다.)\")\n",
    "print(\"대립가설 : pop_density별 revenues의 평균 차이가 적어도 하나 존재한다.\")\n",
    "\n",
    "# 유의 수준 설정\n",
    "print(\"통계적 추론에서 유의수준은 다른 말이 없으면 5%(0.05)로 지정\")\n",
    "\n",
    "# F 검정 통계량값과 유의 수준 비교 및 귀무가설 기각/채택 여부 확인\n",
    "# F_onewayResult(statistic=0.609944214128908, pvalue=0.544572945313452)\n",
    "stats.f_oneway(\n",
    "    df[df['pop_density'] == 'High']['revenues']\n",
    "    , df[df['pop_density'] == 'Medium']['revenues']\n",
    "    , df[df['pop_density'] == 'Low']['revenues']\n",
    ")\n",
    "# p-value가 유의수준 0.05보다 크기 때문에 귀무가설을 기각할 수 없다.\n",
    "# 만약 귀무가설을 기각하게되면, 사후 분석으로 tukey HSD 를 수행\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eba207f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:8:8: 예상하지 못한 기호(symbol)입니다.\n7: \n8: import pandas\n          ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:8:8: 예상하지 못한 기호(symbol)입니다.\n7: \n8: import pandas\n          ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# Q2) google_adwords, facebook, twitter, marketing_total, employees가 \n",
    "#     revenues에 영향을 미치는지 알아보는 회귀분석을 전진선택법을 사용하여 수행하고 결과를 해석하시오.\n",
    "#----------------------------------------------------------------------------------------\n",
    "# R을 이용하면 step 함수를 이용해서 쉽게 해결 가능하지만, python에서는 sklearn에 이러한 stepwise variable selection 관련 빌트인 함수가 없음\n",
    "# 회귀분석은 R을 이용해서 수행하는 것이 나을 것으로 생각됨\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv('./data/모의고사4회/bike_marketing.csv')\n",
    "\n",
    "print(f\"shape={df.shape}, columns={df.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76800877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Q3) 전진선택법을 사용해 변수를 선택한 후 새롭게 생성한 회귀모형에 대한 \n",
    "#     잔차분석을 수행하고 결과를 해석하시오. \n",
    "#---------------------------------------------------------------------------\n",
    "# 잔차분석 => 회귀 모형에 대한 가정이 충족되는지 검정하는 것(잔차의 등분산성, 독립성, 정규성 확인)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24225d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#                      3. 비정형 데이터마이닝 (사용 데이터 : \"instagram_태교여행\")\n",
    "###################################################################################\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# Q1) ‘instagram_태교여행.txt’ 데이터를 읽어온 뒤 숫자, 특수 문자 등을 \n",
    "#     제거하는 전처리 작업을 시행하시오.\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Q2) 전처리된 데이터에서 “태교여행”이란 단어를 사전에 추가하고 명사를 추출해 \n",
    "#     출현빈도 10위까지 막대그래프로 시각화하시오. \n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}