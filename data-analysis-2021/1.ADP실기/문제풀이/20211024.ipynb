{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63edfe14",
   "metadata": {},
   "source": [
    "# 모의고사 4회 문제 풀이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c0a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(142193, 21) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am',\n",
      "       'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',\n",
      "       'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm',\n",
      "       'RainToday', 'RainTomorrow'],\n",
      "      dtype='object')\n",
      "shape=(142193, 16) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm',\n",
      "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
      "       'RainTomorrow'],\n",
      "      dtype='object')\n",
      "shape=(128576, 16) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm',\n",
      "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
      "       'RainTomorrow'],\n",
      "      dtype='object') df3=         Date Location  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
      "0  2008-12-01   Albury     13.4     22.9       0.6           W           44.0   \n",
      "1  2008-12-02   Albury      7.4     25.1       0.0         WNW           44.0   \n",
      "2  2008-12-03   Albury     12.9     25.7       0.0         WSW           46.0   \n",
      "3  2008-12-04   Albury      9.2     28.0       0.0          NE           24.0   \n",
      "4  2008-12-05   Albury     17.5     32.3       1.0           W           41.0   \n",
      "\n",
      "  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Temp9am  \\\n",
      "0        WNW          20.0          24.0         71.0         22.0     16.9   \n",
      "1        WSW           4.0          22.0         44.0         25.0     17.2   \n",
      "2        WSW          19.0          26.0         38.0         30.0     21.0   \n",
      "3          E          11.0           9.0         45.0         16.0     18.1   \n",
      "4         NW           7.0          20.0         82.0         33.0     17.8   \n",
      "\n",
      "   Temp3pm RainToday RainTomorrow  \n",
      "0     21.8        No           No  \n",
      "1     24.3        No           No  \n",
      "2     23.2        No           No  \n",
      "3     26.5        No           No  \n",
      "4     29.7        No           No   describe=             MinTemp        MaxTemp       Rainfall  WindGustSpeed  \\\n",
      "count  128576.000000  128576.000000  128576.000000  128576.000000   \n",
      "mean       12.141033      23.307020       2.299270      40.055679   \n",
      "std         6.427982       7.128457       8.349637      13.525466   \n",
      "min        -8.500000      -4.800000       0.000000       6.000000   \n",
      "25%         7.500000      17.900000       0.000000      31.000000   \n",
      "50%        11.900000      22.800000       0.000000      39.000000   \n",
      "75%        16.800000      28.400000       0.600000      48.000000   \n",
      "max        33.900000      48.100000     367.600000     135.000000   \n",
      "\n",
      "        WindSpeed9am   WindSpeed3pm    Humidity9am    Humidity3pm  \\\n",
      "count  128576.000000  128576.000000  128576.000000  128576.000000   \n",
      "mean       14.236872      18.869424      68.519840      50.915015   \n",
      "std         8.767792       8.603291      19.245898      20.827152   \n",
      "min         0.000000       2.000000       0.000000       0.000000   \n",
      "25%         7.000000      13.000000      56.000000      36.000000   \n",
      "50%        13.000000      19.000000      69.000000      51.000000   \n",
      "75%        20.000000      24.000000      83.000000      65.000000   \n",
      "max        87.000000      87.000000     100.000000     100.000000   \n",
      "\n",
      "             Temp9am        Temp3pm  \n",
      "count  128576.000000  128576.000000  \n",
      "mean       16.970729      21.798451  \n",
      "std         6.529362       6.987518  \n",
      "min        -7.200000      -5.400000  \n",
      "25%        12.200000      16.600000  \n",
      "50%        16.700000      21.300000  \n",
      "75%        21.600000      26.600000  \n",
      "max        40.200000      46.700000  \n",
      "x_train=(90003, 10), x_test=(38573, 10), y_train=(90003,), y_test=(38573,)\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#                      1. 정형 데이터마이닝 (사용 데이터 : weatherAUS)                  \n",
    "###################################################################################\n",
    "#---------------------------------------------------------------------------------------\n",
    "# Q1) 데이터의 요약값을 보고 NA값이 10,000개 이상인 열을 제외하고 남은 변수 중 NA값이 있는 행을 제거하시오. \n",
    "#     그리고 AUS 데이터의 Date 변수를 Date형으로 변환하고, \n",
    "#     전처리가 완료된 weatherAUS 데이터를 train(70%), test(30%) 데이터로 분할하시오.\n",
    "#     (set.seed(6789)를 실행한 후 데이터를 분할하시오.)\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "df = pd.read_csv('./data/모의고사4회/weatherAUS.csv')\n",
    "\n",
    "# 행과 열 개수 확인\n",
    "# 142193개 관측치, 21개 변수\n",
    "print(f'shape={df.shape} columns={df.columns}')\n",
    "#print(df.Location.value_counts())\n",
    "\n",
    "# NA값이 10000개 이상인 열을 제외\n",
    "df2 = df.dropna(\n",
    "    axis = 'columns' # 열을 제외\n",
    "    , thresh =  142193 - 9999   # N개 이상의 non-NA값을 갖고 있는 것만 남김\n",
    "                                # 즉, NA가 아닌 값이 (142193 - 9999) 개수만큼 되는 것만 남기는 것\n",
    ")\n",
    "\n",
    "print(f'shape={df2.shape} columns={df2.columns}')\n",
    "\n",
    "#남은 변수중 NA값이 1개라도 있는 행은 모두 제외\n",
    "df3 = df2.dropna() # dropna의 기본 동작이 모든 컬럼에 대해서 NA가 하나라도 있으면 그 행을 제외\n",
    "\n",
    "print(f'shape={df3.shape} columns={df3.columns} df3={df3.head()} describe={df3.describe()}')\n",
    "\n",
    "# Date 변수를 Date형으로 변환(python datetime을 이용)\n",
    "df3['Date'].apply(lambda x : datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    df3[['MinTemp', 'MaxTemp', 'Rainfall',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm',\n",
    "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm']]\n",
    "    , df3['RainTomorrow']\n",
    "    , train_size = 0.7\n",
    "    , test_size = 0.3\n",
    "    , random_state = 0\n",
    ")\n",
    "\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, y_train={y_train.shape}, y_test={y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca0e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accurate = 0.875\n",
      "test set accurate = 0.832\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------\n",
    "# Q2) train 데이터로 종속변수인 RainTomorrow(다음날의 강수 여부)를 예측하는 분류모델을 \n",
    "#     3개 이상 생성하고 test 데이터에 대한 예측값을 csv파일로 각각 제출하시오.\n",
    "#---------------------------------------------------------------------------------------\n",
    "# K-NN, SVM, DT, 나이브베이즈, 로지스틱 회귀, ANN, 랜덤포레스트, 배깅, 부스팅\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel = 'rbf', C = 10, gamma = 0.1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# DT\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "tree.plot_tree(decision_tree = model)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "86817c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------\n",
    "# Q3) 생성된 3개의 분류모델에 대해 성과분석을 실시하여 정확도를 비교하여 설명하시오. \n",
    "#     또, ROC curve를 그리고 AUC값을 산출하시오.\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8213073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#                     2. 통계분석 (사용 데이터 : bike_marketing)               \n",
    "###################################################################################\n",
    "#---------------------------------------------------------------------------------\n",
    "# Q1) pop_density 변수를 factor형 변수로 변환하고, \n",
    "#     pop_density별 revenues의 평균 차이가 있는지 통계분석을 시행하여 결과를 해석하시오. \n",
    "#     만일 대립가설이 채택된다면 사후분석을 실시하고 결과를 해석하시오.\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# Q2) google_adwords, facebook, twitter, marketing_total, employees가 \n",
    "#     revenues에 영향을 미치는지 알아보는 회귀분석을 전진선택법을 사용하여 수행하고 결과를 해석하시오.\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46eff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Q3) 전진선택법을 사용해 변수를 선택한 후 새롭게 생성한 회귀모형에 대한 \n",
    "#     잔차분석을 수행하고 결과를 해석하시오. \n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c00e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#                      3. 비정형 데이터마이닝 (사용 데이터 : \"instagram_태교여행\")\n",
    "###################################################################################\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# Q1) ‘instagram_태교여행.txt’ 데이터를 읽어온 뒤 숫자, 특수 문자 등을 \n",
    "#     제거하는 전처리 작업을 시행하시오.\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2af072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Q2) 전처리된 데이터에서 “태교여행”이란 단어를 사전에 추가하고 명사를 추출해 \n",
    "#     출현빈도 10위까지 막대그래프로 시각화하시오. \n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
