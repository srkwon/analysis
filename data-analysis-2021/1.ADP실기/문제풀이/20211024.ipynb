{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3633c52",
   "metadata": {},
   "source": [
    "# 모의고사 4회 문제 풀이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce1a6bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(142193, 21) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am',\n",
      "       'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',\n",
      "       'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm',\n",
      "       'RainToday', 'RainTomorrow'],\n",
      "      dtype='object'), describe=             MinTemp        MaxTemp       Rainfall  WindGustSpeed  \\\n",
      "count  141556.000000  141871.000000  140787.000000  132923.000000   \n",
      "mean       12.186400      23.226784       2.349974      39.984292   \n",
      "std         6.403283       7.117618       8.465173      13.588801   \n",
      "min        -8.500000      -4.800000       0.000000       6.000000   \n",
      "25%         7.600000      17.900000       0.000000      31.000000   \n",
      "50%        12.000000      22.600000       0.000000      39.000000   \n",
      "75%        16.800000      28.200000       0.800000      48.000000   \n",
      "max        33.900000      48.100000     371.000000     135.000000   \n",
      "\n",
      "        WindSpeed9am   WindSpeed3pm    Humidity9am    Humidity3pm  \\\n",
      "count  140845.000000  139563.000000  140419.000000  138583.000000   \n",
      "mean       14.001988      18.637576      68.843810      51.482606   \n",
      "std         8.893337       8.803345      19.051293      20.797772   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         7.000000      13.000000      57.000000      37.000000   \n",
      "50%        13.000000      19.000000      70.000000      52.000000   \n",
      "75%        19.000000      24.000000      83.000000      66.000000   \n",
      "max       130.000000      87.000000     100.000000     100.000000   \n",
      "\n",
      "         Pressure9am    Pressure3pm      Cloud9am      Cloud3pm  \\\n",
      "count  128179.000000  128212.000000  88536.000000  85099.000000   \n",
      "mean     1017.653758    1015.258204      4.437189      4.503167   \n",
      "std         7.105476       7.036677      2.887016      2.720633   \n",
      "min       980.500000     977.100000      0.000000      0.000000   \n",
      "25%      1012.900000    1010.400000      1.000000      2.000000   \n",
      "50%      1017.600000    1015.200000      5.000000      5.000000   \n",
      "75%      1022.400000    1020.000000      7.000000      7.000000   \n",
      "max      1041.000000    1039.600000      9.000000      9.000000   \n",
      "\n",
      "             Temp9am        Temp3pm  \n",
      "count  141289.000000  139467.000000  \n",
      "mean       16.987509      21.687235  \n",
      "std         6.492838       6.937594  \n",
      "min        -7.200000      -5.400000  \n",
      "25%        12.300000      16.600000  \n",
      "50%        16.700000      21.100000  \n",
      "75%        21.600000      26.400000  \n",
      "max        40.200000      46.700000  \n",
      "shape=(142193, 16) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm',\n",
      "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
      "       'RainTomorrow'],\n",
      "      dtype='object')\n",
      "shape=(128576, 16) columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm',\n",
      "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm', 'RainToday',\n",
      "       'RainTomorrow'],\n",
      "      dtype='object') df3=         Date Location  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
      "0  2008-12-01   Albury     13.4     22.9       0.6           W           44.0   \n",
      "1  2008-12-02   Albury      7.4     25.1       0.0         WNW           44.0   \n",
      "2  2008-12-03   Albury     12.9     25.7       0.0         WSW           46.0   \n",
      "3  2008-12-04   Albury      9.2     28.0       0.0          NE           24.0   \n",
      "4  2008-12-05   Albury     17.5     32.3       1.0           W           41.0   \n",
      "\n",
      "  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Temp9am  \\\n",
      "0        WNW          20.0          24.0         71.0         22.0     16.9   \n",
      "1        WSW           4.0          22.0         44.0         25.0     17.2   \n",
      "2        WSW          19.0          26.0         38.0         30.0     21.0   \n",
      "3          E          11.0           9.0         45.0         16.0     18.1   \n",
      "4         NW           7.0          20.0         82.0         33.0     17.8   \n",
      "\n",
      "   Temp3pm RainToday RainTomorrow  \n",
      "0     21.8        No           No  \n",
      "1     24.3        No           No  \n",
      "2     23.2        No           No  \n",
      "3     26.5        No           No  \n",
      "4     29.7        No           No  \n",
      "x_train=(90003, 12), x_test=(38573, 12), y_train=(90003,), y_test=(38573,)\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#                      1. 정형 데이터마이닝 (사용 데이터 : weatherAUS)                  \n",
    "###################################################################################\n",
    "#---------------------------------------------------------------------------------------\n",
    "# Q1) 데이터의 요약값을 보고 NA값이 10,000개 이상인 열을 제외하고 남은 변수 중 NA값이 있는 행을 제거하시오. \n",
    "#     그리고 AUS 데이터의 Date 변수를 Date형으로 변환하고, \n",
    "#     전처리가 완료된 weatherAUS 데이터를 train(70%), test(30%) 데이터로 분할하시오.\n",
    "#     (set.seed(6789)를 실행한 후 데이터를 분할하시오.)\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_csv('./data/모의고사4회/weatherAUS.csv')\n",
    "\n",
    "# 행과 열 개수 확인\n",
    "# 142193개 관측치, 21개 변수\n",
    "print(f'shape={df.shape} columns={df.columns}, describe={df.describe()}')\n",
    "#print(df.Location.value_counts())\n",
    "\n",
    "# NA값이 10000개 이상인 열을 제외\n",
    "df2 = df.dropna(\n",
    "    axis = 'columns' # 열을 제외\n",
    "    , thresh =  142193 - 9999   # N개 이상의 non-NA값을 갖고 있는 것만 남김\n",
    "                                # 즉, NA가 아닌 값이 (142193 - 9999) 개수만큼 되는 것만 남기는 것\n",
    ")\n",
    "\n",
    "print(f'shape={df2.shape} columns={df2.columns}')\n",
    "\n",
    "#남은 변수중 NA값이 1개라도 있는 행은 모두 제외\n",
    "df3 = df2.dropna() # dropna의 기본 동작이 모든 컬럼에 대해서 NA가 하나라도 있으면 그 행을 제외\n",
    "\n",
    "print(f'shape={df3.shape} columns={df3.columns} df3={df3.head()}')\n",
    "\n",
    "# Date 변수를 Date형으로 변환(python datetime을 이용)\n",
    "df3['Date'].apply(lambda x : datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    df3[['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
    "       'WindGustSpeed', 'WindSpeed3pm','WindSpeed9am', 'WindSpeed3pm',\n",
    "       'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm']]\n",
    "    , df3['RainTomorrow']\n",
    "    , train_size = 0.7\n",
    "    , test_size = 0.3\n",
    "    , random_state = 0\n",
    ")\n",
    "\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, y_train={y_train.shape}, y_test={y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2c285d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'SE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-7033e5ae0819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# KNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m             X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n\u001b[1;32m-> 1132\u001b[1;33m                                        multi_output=True)\n\u001b[0m\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'SE'"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------\n",
    "# Q2) train 데이터로 종속변수인 RainTomorrow(다음날의 강수 여부)를 예측하는 분류모델을 \n",
    "#     3개 이상 생성하고 test 데이터에 대한 예측값을 csv파일로 각각 제출하시오.\n",
    "#---------------------------------------------------------------------------------------\n",
    "# K-NN, SVM, DT, 나이브베이즈, 로지스틱 회귀, ANN, 랜덤포레스트, 배깅, 부스팅\n",
    "\n",
    "\n",
    "# KNN\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b28dcaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------\n",
    "# Q3) 생성된 3개의 분류모델에 대해 성과분석을 실시하여 정확도를 비교하여 설명하시오. \n",
    "#     또, ROC curve를 그리고 AUC값을 산출하시오.\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#                     2. 통계분석 (사용 데이터 : bike_marketing)               \n",
    "###################################################################################\n",
    "#---------------------------------------------------------------------------------\n",
    "# Q1) pop_density 변수를 factor형 변수로 변환하고, \n",
    "#     pop_density별 revenues의 평균 차이가 있는지 통계분석을 시행하여 결과를 해석하시오. \n",
    "#     만일 대립가설이 채택된다면 사후분석을 실시하고 결과를 해석하시오.\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "# Q2) google_adwords, facebook, twitter, marketing_total, employees가 \n",
    "#     revenues에 영향을 미치는지 알아보는 회귀분석을 전진선택법을 사용하여 수행하고 결과를 해석하시오.\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91001ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Q3) 전진선택법을 사용해 변수를 선택한 후 새롭게 생성한 회귀모형에 대한 \n",
    "#     잔차분석을 수행하고 결과를 해석하시오. \n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdfa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#                      3. 비정형 데이터마이닝 (사용 데이터 : \"instagram_태교여행\")\n",
    "###################################################################################\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# Q1) ‘instagram_태교여행.txt’ 데이터를 읽어온 뒤 숫자, 특수 문자 등을 \n",
    "#     제거하는 전처리 작업을 시행하시오.\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------\n",
    "# Q2) 전처리된 데이터에서 “태교여행”이란 단어를 사전에 추가하고 명사를 추출해 \n",
    "#     출현빈도 10위까지 막대그래프로 시각화하시오. \n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
