{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6ffd6b",
   "metadata": {},
   "source": [
    "# 지도학습(분류)\n",
    "- 데이터 분석 프로세스\n",
    "  - 데이터 수집 -> 데이터 탐색 및 준비 -> 모델 훈련 -> 모델 성능 평가 -> 모델 성능 개선\n",
    "- KNN(K최근접이웃)\n",
    "  - 제일 먼저 K개의 같은 범주로 구분되는 쪽으로 데이터 샘플을 분류하는 방식의 기법\n",
    "  - 장점\n",
    "    - 단순하고 효율적, 직관적\n",
    "    - 분포에 대한 가정이 없음\n",
    "    - 훈련이 빠름\n",
    "  - 단점\n",
    "    - 적절한 K를 선택 필요\n",
    "- SVM(서포트벡터머신)\n",
    "  - 초평면(하이퍼플래인) 기반으로 데이터를 분류하는 방식의 기법\n",
    "    - 최대 마진 초평면(MMH, Maximum Margin Hyperplane)\n",
    "  - 커널 함수(보통 RBF 함수)를 이용\n",
    "  - 장점\n",
    "    - 분류, 회귀 모두 적용 가능\n",
    "    - 노이즈, 과적합에 영향이 거의 없음\n",
    "  - 단점\n",
    "    - 적절한 파라미터 조합 테스트 필요(커널 함수 등)\n",
    "- DT(결정트리)\n",
    "  - 트리 방식으로 데이터셋의 순수도를 최대화하는 방향으로 트리를 성장시키면서 분류하는 방식의 기법\n",
    "    - C5.0, CART 알고리즘 등이 사용\n",
    "  - 장점\n",
    "    - 분류, 회귀 모두 적용 가능\n",
    "    - 직관적으로 모델을 이해할 수 있음\n",
    "  - 단점\n",
    "    - 모델이 과적합, 과소적합되기 쉬움\n",
    "- 배깅\n",
    "  - \n",
    "- 부스팅\n",
    "  - \n",
    "- 랜덤포레스트\n",
    "  - \n",
    "- 나이브베이즈\n",
    "- 로지스틱회귀\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bb51db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 요약 확인\n",
      " shape=(142193, 21)\n",
      " columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am',\n",
      "       'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',\n",
      "       'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm',\n",
      "       'RainToday', 'RainTomorrow'],\n",
      "      dtype='object')\n",
      "컬럼별 NA 개수 확인\n",
      "Date                 0\n",
      "Location             0\n",
      "MinTemp            637\n",
      "MaxTemp            322\n",
      "Rainfall          1406\n",
      "WindGustDir       9330\n",
      "WindGustSpeed     9270\n",
      "WindDir9am       10013\n",
      "WindDir3pm        3778\n",
      "WindSpeed9am      1348\n",
      "WindSpeed3pm      2630\n",
      "Humidity9am       1774\n",
      "Humidity3pm       3610\n",
      "Pressure9am      14014\n",
      "Pressure3pm      13981\n",
      "Cloud9am         53657\n",
      "Cloud3pm         57094\n",
      "Temp9am            904\n",
      "Temp3pm           2726\n",
      "RainToday         1406\n",
      "RainTomorrow         0\n",
      "dtype: int64\n",
      "컬럼별 NA 개수 확인\n",
      "Date             0\n",
      "Location         0\n",
      "MinTemp          0\n",
      "MaxTemp          0\n",
      "Rainfall         0\n",
      "WindGustDir      0\n",
      "WindGustSpeed    0\n",
      "WindDir9am       0\n",
      "WindDir3pm       0\n",
      "WindSpeed9am     0\n",
      "WindSpeed3pm     0\n",
      "Humidity9am      0\n",
      "Humidity3pm      0\n",
      "Pressure9am      0\n",
      "Pressure3pm      0\n",
      "Cloud9am         0\n",
      "Cloud3pm         0\n",
      "Temp9am          0\n",
      "Temp3pm          0\n",
      "RainToday        0\n",
      "RainTomorrow     0\n",
      "dtype: int64 shape=(71045, 21)\n",
      " columns=Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
      "       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am',\n",
      "       'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',\n",
      "       'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm',\n",
      "       'RainToday', 'RainTomorrow'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-dfa7ed675cb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# KNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"train set accurate = {model.score(x_train, y_train):0.3f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m             X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n\u001b[1;32m-> 1132\u001b[1;33m                                        multi_output=True)\n\u001b[0m\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 645\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\srkwon\\0.repo\\analysis\\data-analysis-2021\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n\u001b[1;32m---> 99\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m    100\u001b[0m             )\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "df = pd.read_csv('./data/weatherAUS.csv')\n",
    "\n",
    "# 행과 열 개수 확인\n",
    "# 142193개 관측치, 21개 변수\n",
    "print(f'데이터 요약 확인\\n shape={df.shape}\\n columns={df.columns}')\n",
    "print(f\"컬럼별 NA 개수 확인\\n{df.isnull().sum()}\")\n",
    "\n",
    "# 행에 NA가 하나만 있어도 삭제\n",
    "df2 = df.dropna()\n",
    "\n",
    "print(f\"컬럼별 NA 개수 확인\\n{df2.isnull().sum()} shape={df2.shape}\\n columns={df2.columns}\")\n",
    "\n",
    "# NA값이 10000개 이상인 열을 제외\n",
    "df3 = df.dropna(\n",
    "    axis = 'columns' # 열을 제외\n",
    "    , thresh =  142193 - 9999   # N개 이상의 non-NA값을 갖고 있는 것만 남김\n",
    "                                # 즉, NA가 아닌 값이 (142193 - 9999) 개수만큼 되는 것만 남기는 것\n",
    ")\n",
    "\n",
    "# print(f'shape={df3.shape} columns={df3.columns} df3={df3.head()} describe={df3.describe()}')\n",
    "\n",
    "# Date 변수를 Date형으로 변환(python datetime을 이용)\n",
    "df3['Date'].apply(lambda x : datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    df3[['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Temp9am', 'Temp3pm']]\n",
    "    , df3['RainTomorrow']\n",
    "    , train_size = 0.7\n",
    "    , test_size = 0.3\n",
    "    , random_state = 0\n",
    ")\n",
    "\n",
    "# print(f\"x_train={x_train.shape}, x_test={x_test.shape}, y_train={y_train.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "# Q2) train 데이터로 종속변수인 RainTomorrow(다음날의 강수 여부)를 예측하는 분류모델을 \n",
    "#     3개 이상 생성하고 test 데이터에 대한 예측값을 csv파일로 각각 제출하시오.\n",
    "#---------------------------------------------------------------------------------------\n",
    "# K-NN, SVM, DT, 나이브베이즈, 로지스틱 회귀, ANN, 랜덤포레스트, 배깅, 부스팅\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel = 'rbf', C = 10, gamma = 0.1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# DT\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "tree.plot_tree(decision_tree = model)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f\"train set accurate = {model.score(x_train, y_train):0.3f}\")\n",
    "print(f\"test set accurate = {model.score(x_test, y_test):0.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e417c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
